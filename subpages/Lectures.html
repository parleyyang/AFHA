<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" href="Lectures.css" />
    <link rel="preconnect" href="https://fonts.gstatic.com" />
    <link
      href="https://fonts.googleapis.com/css2?family=Crete+Round&family=Raleway:wght@400;700&display=swap"
      rel="stylesheet"
    />
  </head>
  <body>
    <nav>
        <h2><a href  ="../index.html"class = "menubutton">Home</a></h2>
        <h2><a href  ="About.html"class = "menubutton">About</a></h2>
        <h2><a href  ="People.html"class = "menubutton">People</a></h2>
        <div class = 'dropdown'>
          <h2><a href  ="#" class = "menubutton">Research</a></h2>
          <div class="dropdown-content">
              <a href="PhDs.html">PhD Projects</a>
              <a href="Code.html">Code</a>
    </nav>

    <div class="container vlight">

      <h1 style = "font-size: 36px; margin-top: 150px;">On the mysteries of artificial intelligence - do we know what we are doing?</h1>
      <p style = "font-style:italic;">Lecture given at the University of Oslo 22 May 2019.<br> <br></p>
      <h2>Abstract:</h2>
      <p>Artificial Intelligence has the potential to revolutionise our way of living. We may have self-driving cars in the future and your doctor may be replaced by AI algorithms. The latter is not science fiction anymore. Indeed, the US Food and Drug Administration (FDA) has already approved AI techniques for automated diagnosis without the input of a human clinician. <br> <br>
        Moreover, modern AI research has been likened to alchemy because of its trial and error approach and lack of foundations. Indeed, Ali Rahimi, an award winning researcher at Google, sparked an intense debate in the community when he used the alchemy analogy and criticised the current state-of-the-art AI and machine learning for its lack of fundamental scientific approach. <br> <br>
        We will in this talk discuss the lack of foundations in modern AI, its curious non-human behaviour and the slightly philosophical dilemmas that follow. Finally, we will try to shed some light on the basic question in the AI debate: do we know what we are doing?</p>
        <h2 style = "margin-top: 50px; margin-bottom: 200px;"><a href  ="http://www.damtp.cam.ac.uk/research/afha/lectures/talks2019/Oslo_Deep_Learning_Vitenskaps_teori_May2019.pdf" class = "bodylinkhover">Slides</a></h2>

        </p> 

    </div>


    <div class="container dark">
  
              <h1 style = "font-size: 36px; margin-top: 150px;">Trends in mathematics of information -- Deep learning, artificial intelligence and compressed sensing</h1>
              <p style = "font-style:italic; padding: 3px;">Lecture series given at the University of Oslo May 14-16 2018, together with Vegard Antun.<br> <br></p>
              <h2>Abstract:</h2>
              <p style = "font-weight:500; font-family: Raleway, sans-serif;">In the last decade there have been two major breakthroughs in mathematics of information and data science that stand out: the introduction of compressed sensing in the mid 2000s and the documented success of deep learning from 2012 and onwards. In this series of talks we will give an overview of both of these techniques, provide mathematical background and plenty of practical examples.<br> <br>
                Deep learning is now the state-of-the-art method for classification and recognition. Its success is unmatched by a considerable margin and its performance is now referred to as super-human. This opens up for endless applications where automated recognition and classification is important such as for driverless cars, in surveillance, in image and speech recognition etc. Given that deep learning outperforms humans on many tasks one faces the question: have we reached artificial intelligence? I will consider this question in view of Smale's 18th problem and Turing's paper from 1950, where he introduces the imitation game. When considering this question, a rather fascinating issue is revealed. Indeed, deep learning becomes completely unstable. This phenomenon has both philosophical and practical consequences. <br> <br>
                Compressed sensing and sparse regularisations have in many ways changed the way one approaches medical imaging and inverse problems. However, interestingly, deep learning can also be used in these cases. The use of deep learning in inverse problems is a rather new concept, and the community has just started investigating the many possibilities. We will discuss several of the deep learning approaches and compare the results with compressed sensing. When doing so, one discovers an alluring phenomenon: deep learning may produce completely unstable reconstruction methods for inverse problems.</p>
                <h2 style = "margin-top: 50px; margin-bottom: 200px;"><a href  ="http://www.damtp.cam.ac.uk/research/afha/lectures/talks2019/Oslo_Deep_Learning_Vitenskaps_teori_May2019.pdf" class = "bodylinkhover">Slides</a></h2>
            </div>

            <div class="container vlight">

                <h1 style = "font-size: 36px; margin-top: 100px;">Compressed Sensing - Applications and Theory</h1>
                <p style = "font-weight: bold;">University of Oslo, 23 -25 March, 2015<br> <br> </p> 
                <p style = "font-style: italic;">Vilhelm Bjerknes' Hus (Auditorium 2), Blindern: 12:15-14:00 Monday and Tuesday, 14:15-16:00 Wednesday<br> </p>
                <h2>Abstract:</h2>
                <p>This will be a short 6 lectures course on contemporary compressed sensing designed for researchers from engineering, physics, mathematics, life sciences etc. on how to get compressed sensing to work in their own field.<br> <br>
                    Compressed sensing is a theory of randomisation, sparsity and non-linear optimisation techniques that breaks traditional barriers in sampling theory. Since its introduction in 2004 the field has exploded and is rapidly growing and changing. The course will be introductory but aims at providing the latest developments in the field. The course will focus on how to get compressed sensing to work in real life applications and is aimed at students, post docs and professors who want to learn how compressed sensing can be used in their research. The course is designed to be very accessible to people outside the math department and applications will be emphasised. Typical examples include Magnetic Resonance Imaging (MRI), Computerised Tomography (CT), Electron microscopy, Fluorescence microscopy, Helium atom scattering, radio interferometry and imaging in general. <br> <br>
                    For a recent article in Apollon about compressed sensing see: <a href = "http://www.apollon.uio.no/artikler/2015/1_beregninger_straaling.html"> Apollon (in Norwegian) </a></p>
                  <h2 style = "margin-top: 50px;"><a href  ="http://www.damtp.cam.ac.uk/research/afha/lectures/talks2019/Oslo_Deep_Learning_Vitenskaps_teori_May2019.pdf" class = "bodylinkhover">Slides</a></h2>
                  <h2>References:</h2><p>The course will be based on slides and references to books and papers:<br>
                    <a href = "http://www.damtp.cam.ac.uk/research/afha/anders/teaching/CH1_EK.pdf">Compressed Sensing </a> (Eldar, Kutyniok), CUP 2012, <br>
                    <a href = "http://www.cis.pku.edu.cn/faculty/vision/zlin/A%20Mathematical%20Introduction%20to%20Compressive%20Sensing.pdf">A Mathematical Introduction to Compressive Sensing </a> <br><br>
                    <p> The books mentioned above are excellent for covering compressed sensing up to about 2011. Chapter 1 in EK is an excellent introduction to the basics. The field has changes considerably since then, and we will emphasise more recent developments. Thus, the following papers will also be useful:</p>
                    <ul style = "margin-bottom: 200px;"> 
                       <a href = "http://www.damtp.cam.ac.uk/research/afha/bogdan/Asymptotic_10a.pdf"> <li> On asymptotic structure in compressed sensing</li></a>
                       <a href = "http://arxiv.org/pdf/1302.0561v4.pdf"> <li> Breaking the coherence barrier: A new theory for compressed sensing</li></a>
                       <a href = "http://www.damtp.cam.ac.uk/research/afha/anders/Book_chapter19.pdf"> <li> The quest for optimal sampling: computationally efficient, structure-exploiting measurements for compressed sensing</li></a>
                       <a href = "http://www.damtp.cam.ac.uk/research/afha/anders/Book_chapter19.pdf"> <li> Generalized sampling: stable reconstructions, inverse problems and compressed sensing over the continuum</li></a>


                    </ul>
              </div>

              <div class="container dark">
                <h1 style = "font-size: 36px; margin-top: 100px;">Workshops</h1>
                <a href = "http://www.damtp.cam.ac.uk/research/afha/workshops/cid2014.1.html"><p>Computations in infinite dimensions: Challenges in a continuous world</p></a> <br>
                <p style = "margin-bottom: 300px;">Kavli Royal Society International Centre at Chicheley Hall, 30 June - 1 July, 2014. </p>
              </div>
  </body>
</html>
